---
layout: post
title:  "一致性算法在互联网场景中的应用"
date:   2018-08-25 23:30:00 +0800
categories: tech
---
世界上只有一种一致性算法就是`Paxos`(帕克索斯)。在工程上通常使用其简化版本的`Raft`算法。算法的核心思想都是，在保证**CP**的前提下，只要大多数的节点可以互联，系统便一直处于可用状态(A)。

## 背景

[分布式系统的事务处理]的文章，讲述了常见的处理一致性问题的方法。一致性的问题主要来源于：

1. 一台服务器的性能不足以提供足够的能力服务于所有的网络请求。     -- 需要扩容，解决性能问题  
2. 我们总是害怕我们的这台服务器停机，造成服务不可用或是数据丢失。 -- 需要扩容，解决单点问题

因此，通常的做法是：

1. 数据分区：就是把数据分块放在不同的服务器上（如：uid % 16，一致性哈希等）。
2. 数据镜像：让所有的服务器都有相同的数据，提供相当的服务。

通过上述做法，可以解决性能(A)和单点(p)问题，但是却无法在分区的情况下保证数据的一致性(C)。即，`CAP`只能满足其二。

![Transaction-Across-DataCenter](https://github.com/gerryyang/mac-utils/raw/master/tools/VPS/jekyll/my-jekyll-project/assets/images/201808/Transaction-Across-DataCenter.png)


## 可用性评估

系统的可用性(Availability) = MTBF(平均故障间隔时间) / MTBF + MTTR(平均故障修复时间)

业界通常用N个9来表示系统的可用性。例如，`99.999%`代表5个9的可用性，表示**全年不可用时间**必须保证在`5.26分钟`以内。


## Raft

`Raft`属于强一致性算法(CP)，在牺牲一定程度的可用性(A)上，来保证一致性(C)。

`Raft`算法的特点：

1. 强一致性。leader节点的数据最全。
2. 高可靠性。committed的日志不会被修改，少于一半的磁盘故障数据不会丢失。
3. 高可用性。少量节点故障或网络异常不影响可用性。
4. 高性能。大多数节点成功即可。

`Raft`的处理流程：

1. 都使用`timeout`来重新选择`leader`。
2. 采用`quorum`(法定人数)来确定整个系统的一致性，一般是集群中半数以上的服务器。zk里还提供了带权重的`quorum`实现。
3. 都由`leader`来发起写操作。
4. 都采用心跳检测存活性。
5. leader election都采用先到先得的投票方式。



# Refer

1. [分布式系统的事务处理]



[分布式系统的事务处理]: https://coolshell.cn/articles/10910.html